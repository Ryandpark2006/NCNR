{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c67c708-6804-4cdb-877a-f4704c26a5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Elapsed time (minutes)</th>\n",
       "      <th>Setpoint (K)</th>\n",
       "      <th>Sensor A (K)</th>\n",
       "      <th>Sensor B (K)</th>\n",
       "      <th>Heater Output % (0-100)</th>\n",
       "      <th>Heater Range (integer 0-5)</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Sensor C (K) or sensor A (sensor unit)</th>\n",
       "      <th>Sensor D (K) or sensor B (sensor unit)</th>\n",
       "      <th>CCR_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/20/2014 03:02:25 PM</td>\n",
       "      <td>0.984532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.022</td>\n",
       "      <td>282.108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60091</td>\n",
       "      <td>0.60072</td>\n",
       "      <td>./CCR-05/2014/20140320.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03/20/2014 03:02:30 PM</td>\n",
       "      <td>1.068290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.024</td>\n",
       "      <td>282.110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60091</td>\n",
       "      <td>0.60071</td>\n",
       "      <td>./CCR-05/2014/20140320.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03/20/2014 03:02:35 PM</td>\n",
       "      <td>1.151215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.026</td>\n",
       "      <td>282.112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60090</td>\n",
       "      <td>0.60071</td>\n",
       "      <td>./CCR-05/2014/20140320.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/20/2014 03:02:40 PM</td>\n",
       "      <td>1.234957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.028</td>\n",
       "      <td>282.115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60090</td>\n",
       "      <td>0.60070</td>\n",
       "      <td>./CCR-05/2014/20140320.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03/20/2014 03:02:45 PM</td>\n",
       "      <td>1.317882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282.030</td>\n",
       "      <td>282.117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.60089</td>\n",
       "      <td>0.60070</td>\n",
       "      <td>./CCR-05/2014/20140320.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395695</th>\n",
       "      <td>12/30/2019 10:17:37 AM</td>\n",
       "      <td>4091.354468</td>\n",
       "      <td>300.0</td>\n",
       "      <td>298.495</td>\n",
       "      <td>300.000</td>\n",
       "      <td>12.5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.56314</td>\n",
       "      <td>0.55966</td>\n",
       "      <td>./CCR-17/2019/20191227.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395696</th>\n",
       "      <td>12/30/2019 10:17:42 AM</td>\n",
       "      <td>4091.437382</td>\n",
       "      <td>300.0</td>\n",
       "      <td>298.496</td>\n",
       "      <td>300.000</td>\n",
       "      <td>12.5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.56313</td>\n",
       "      <td>0.55966</td>\n",
       "      <td>./CCR-17/2019/20191227.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395697</th>\n",
       "      <td>12/30/2019 10:17:47 AM</td>\n",
       "      <td>4091.521134</td>\n",
       "      <td>300.0</td>\n",
       "      <td>298.497</td>\n",
       "      <td>300.000</td>\n",
       "      <td>12.5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.56313</td>\n",
       "      <td>0.55966</td>\n",
       "      <td>./CCR-17/2019/20191227.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395698</th>\n",
       "      <td>12/30/2019 10:17:52 AM</td>\n",
       "      <td>4091.604055</td>\n",
       "      <td>300.0</td>\n",
       "      <td>298.498</td>\n",
       "      <td>300.000</td>\n",
       "      <td>12.5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.56313</td>\n",
       "      <td>0.55966</td>\n",
       "      <td>./CCR-17/2019/20191227.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395699</th>\n",
       "      <td>12/30/2019 10:17:57 AM</td>\n",
       "      <td>4091.687624</td>\n",
       "      <td>300.0</td>\n",
       "      <td>298.498</td>\n",
       "      <td>300.001</td>\n",
       "      <td>12.5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.56313</td>\n",
       "      <td>0.55966</td>\n",
       "      <td>./CCR-17/2019/20191227.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395700 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Timestamp  Elapsed time (minutes)  Setpoint (K)  \\\n",
       "0       03/20/2014 03:02:25 PM                0.984532           0.0   \n",
       "1       03/20/2014 03:02:30 PM                1.068290           0.0   \n",
       "2       03/20/2014 03:02:35 PM                1.151215           0.0   \n",
       "3       03/20/2014 03:02:40 PM                1.234957           0.0   \n",
       "4       03/20/2014 03:02:45 PM                1.317882           0.0   \n",
       "...                        ...                     ...           ...   \n",
       "395695  12/30/2019 10:17:37 AM             4091.354468         300.0   \n",
       "395696  12/30/2019 10:17:42 AM             4091.437382         300.0   \n",
       "395697  12/30/2019 10:17:47 AM             4091.521134         300.0   \n",
       "395698  12/30/2019 10:17:52 AM             4091.604055         300.0   \n",
       "395699  12/30/2019 10:17:57 AM             4091.687624         300.0   \n",
       "\n",
       "        Sensor A (K)  Sensor B (K)  Heater Output % (0-100)  \\\n",
       "0            282.022       282.108                      0.0   \n",
       "1            282.024       282.110                      0.0   \n",
       "2            282.026       282.112                      0.0   \n",
       "3            282.028       282.115                      0.0   \n",
       "4            282.030       282.117                      0.0   \n",
       "...              ...           ...                      ...   \n",
       "395695       298.495       300.000                     12.5   \n",
       "395696       298.496       300.000                     12.5   \n",
       "395697       298.497       300.000                     12.5   \n",
       "395698       298.498       300.000                     12.5   \n",
       "395699       298.498       300.001                     12.5   \n",
       "\n",
       "        Heater Range (integer 0-5)     Slope  Intercept  \\\n",
       "0                                5  1.000000   1.000000   \n",
       "1                                5  1.000000   1.000000   \n",
       "2                                5  1.000000   1.000000   \n",
       "3                                5  1.000000   1.000000   \n",
       "4                                5  1.000000   1.000000   \n",
       "...                            ...       ...        ...   \n",
       "395695                           5 -0.000012   0.000076   \n",
       "395696                           5 -0.000012   0.000071   \n",
       "395697                           5 -0.000008   0.000040   \n",
       "395698                           5 -0.000004   0.000008   \n",
       "395699                           5 -0.000003  -0.000006   \n",
       "\n",
       "        Sensor C (K) or sensor A (sensor unit)  \\\n",
       "0                                      0.60091   \n",
       "1                                      0.60091   \n",
       "2                                      0.60090   \n",
       "3                                      0.60090   \n",
       "4                                      0.60089   \n",
       "...                                        ...   \n",
       "395695                                 0.56314   \n",
       "395696                                 0.56313   \n",
       "395697                                 0.56313   \n",
       "395698                                 0.56313   \n",
       "395699                                 0.56313   \n",
       "\n",
       "        Sensor D (K) or sensor B (sensor unit)                      CCR_ID  \n",
       "0                                      0.60072  ./CCR-05/2014/20140320.txt  \n",
       "1                                      0.60071  ./CCR-05/2014/20140320.txt  \n",
       "2                                      0.60071  ./CCR-05/2014/20140320.txt  \n",
       "3                                      0.60070  ./CCR-05/2014/20140320.txt  \n",
       "4                                      0.60070  ./CCR-05/2014/20140320.txt  \n",
       "...                                        ...                         ...  \n",
       "395695                                 0.55966  ./CCR-17/2019/20191227.txt  \n",
       "395696                                 0.55966  ./CCR-17/2019/20191227.txt  \n",
       "395697                                 0.55966  ./CCR-17/2019/20191227.txt  \n",
       "395698                                 0.55966  ./CCR-17/2019/20191227.txt  \n",
       "395699                                 0.55966  ./CCR-17/2019/20191227.txt  \n",
       "\n",
       "[395700 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"CCR_final.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d12606-aabf-4f42-859f-de31fbb063f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /storage/conda/mambaforge/envs/jupyterhub/lib/python3.10/site-packages (from tensorflow) (3.8.0)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow)\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorflow) (1.24.3)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in /storage/conda/mambaforge/envs/jupyterhub/lib/python3.10/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorflow) (4.23.3)\n",
      "Requirement already satisfied: setuptools in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /storage/conda/mambaforge/envs/jupyterhub/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /storage/conda/mambaforge/envs/jupyterhub/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow)\n",
      "  Using cached google_auth-2.21.0-py2.py3-none-any.whl (182 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow)\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /storage/rwp2/.local/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.2.3)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow)\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in /storage/conda/mambaforge/envs/jupyterhub/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.14)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /storage/conda/mambaforge/envs/jupyterhub/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /storage/conda/mambaforge/envs/jupyterhub/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/conda/mambaforge/envs/jupyterhub/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /storage/conda/mambaforge/envs/jupyterhub/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /storage/rwp2/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /storage/conda/mambaforge/envs/jupyterhub/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "\u001b[33mWARNING: Error parsing requirements for wrapspawner: [Errno 13] Permission denied: '/storage/conda/mambaforge/envs/jupyterhub/lib/python3.10/site-packages/wrapspawner-1.0.1.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: rsa, pyasn1-modules, opt-einsum, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "\u001b[33m  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/storage/rwp2/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script markdown_py is installed in '/storage/rwp2/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/storage/rwp2/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tensorboard is installed in '/storage/rwp2/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/storage/rwp2/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 gast-0.4.0 google-auth-2.21.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.56.0 keras-2.13.1 markdown-3.4.3 opt-einsum-3.3.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorflow-2.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1184b11d-d97e-4eca-a464-79d8c53becc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2181501/3399874454.py:25: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  timestamps = pd.to_datetime(df['Timestamp'])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: './CCR-05/2014/20140320.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m timestamps \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     26\u001b[0m values \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m---> 27\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Fill missing values in the time series using linear interpolation\u001b[39;00m\n\u001b[1;32m     30\u001b[0m series \u001b[38;5;241m=\u001b[39m fill_missing_values(series)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/darts/timeseries.py:714\u001b[0m, in \u001b[0;36mTimeSeries.from_dataframe\u001b[0;34m(cls, df, time_col, value_cols, fill_missing_dates, freq, fillna_value, static_covariates, hierarchy)\u001b[0m\n\u001b[1;32m    705\u001b[0m     time_index\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m time_col \u001b[38;5;28;01mif\u001b[39;00m time_col \u001b[38;5;28;01melse\u001b[39;00m DIMS[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    707\u001b[0m xa \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(\n\u001b[1;32m    708\u001b[0m     series_df\u001b[38;5;241m.\u001b[39mvalues[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis],\n\u001b[1;32m    709\u001b[0m     dims\u001b[38;5;241m=\u001b[39m(time_index\u001b[38;5;241m.\u001b[39mname,) \u001b[38;5;241m+\u001b[39m DIMS[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:],\n\u001b[1;32m    710\u001b[0m     coords\u001b[38;5;241m=\u001b[39m{time_index\u001b[38;5;241m.\u001b[39mname: time_index, DIMS[\u001b[38;5;241m1\u001b[39m]: series_df\u001b[38;5;241m.\u001b[39mcolumns},\n\u001b[1;32m    711\u001b[0m     attrs\u001b[38;5;241m=\u001b[39m{STATIC_COV_TAG: static_covariates, HIERARCHY_TAG: hierarchy},\n\u001b[1;32m    712\u001b[0m )\n\u001b[0;32m--> 714\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_xarray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_missing_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_missing_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfillna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfillna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/darts/timeseries.py:446\u001b[0m, in \u001b[0;36mTimeSeries.from_xarray\u001b[0;34m(cls, xa, fill_missing_dates, freq, fillna_value)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(xa_)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[43mxa_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/common.py:1504\u001b[0m, in \u001b[0;36mDataWithCoords.astype\u001b[0;34m(self, dtype, order, casting, subok, copy, keep_attrs)\u001b[0m\n\u001b[1;32m   1501\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(order\u001b[38;5;241m=\u001b[39morder, casting\u001b[38;5;241m=\u001b[39mcasting, subok\u001b[38;5;241m=\u001b[39msubok, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   1502\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m-> 1504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_ufunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduck_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallowed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/computation.py:1171\u001b[0m, in \u001b[0;36mapply_ufunc\u001b[0;34m(func, input_core_dims, output_core_dims, exclude_dims, vectorize, join, dataset_join, dataset_fill_value, keep_attrs, kwargs, dask, output_dtypes, output_sizes, meta, dask_gufunc_kwargs, *args)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;66;03m# feed DataArray apply_variable_ufunc through apply_dataarray_vfunc\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, DataArray) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m-> 1171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_dataarray_vfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariables_vfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;66;03m# feed Variables directly through apply_variable_ufunc\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, Variable) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/computation.py:288\u001b[0m, in \u001b[0;36mapply_dataarray_vfunc\u001b[0;34m(func, signature, join, exclude_dims, keep_attrs, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m result_coords \u001b[38;5;241m=\u001b[39m build_output_coords(\n\u001b[1;32m    284\u001b[0m     args, signature, exclude_dims, combine_attrs\u001b[38;5;241m=\u001b[39mkeep_attrs\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    287\u001b[0m data_vars \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(a, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 288\u001b[0m result_var \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    291\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    292\u001b[0m         DataArray(variable, coords, name\u001b[38;5;241m=\u001b[39mname, fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m variable, coords \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(result_var, result_coords)\n\u001b[1;32m    294\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/computation.py:739\u001b[0m, in \u001b[0;36mapply_variable_ufunc\u001b[0;34m(func, signature, exclude_dims, dask, output_dtypes, vectorize, keep_attrs, dask_gufunc_kwargs, *args)\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vectorize:\n\u001b[1;32m    735\u001b[0m         func \u001b[38;5;241m=\u001b[39m _vectorize(\n\u001b[1;32m    736\u001b[0m             func, signature, output_dtypes\u001b[38;5;241m=\u001b[39moutput_dtypes, exclude_dims\u001b[38;5;241m=\u001b[39mexclude_dims\n\u001b[1;32m    737\u001b[0m         )\n\u001b[0;32m--> 739\u001b[0m result_data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    742\u001b[0m     result_data \u001b[38;5;241m=\u001b[39m (result_data,)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xarray/core/duck_array_ops.py:197\u001b[0m, in \u001b[0;36mastype\u001b[0;34m(data, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current version of sparse does not support the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcasting\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument. It will be ignored in the call to astype().\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    193\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    195\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcasting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: './CCR-05/2014/20140320.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from darts import TimeSeries, metrics\n",
    "from darts.utils.missing_values import fill_missing_values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.models import (\n",
    "    RNNModel,\n",
    "    TCNModel,\n",
    "    TransformerModel,\n",
    "    NBEATSModel,\n",
    "    BlockRNNModel,\n",
    "    VARIMA,  \n",
    ")\n",
    "\n",
    "# Load your dataset into a DataFrame (replace 'your_dataset.csv' with your actual file path or name)\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Convert the DataFrame to a Darts TimeSeries object\n",
    "timestamps = pd.to_datetime(df['Timestamp'])\n",
    "values = df.drop('Timestamp', axis=1).values\n",
    "series = TimeSeries.from_dataframe(df, time_col='Timestamp', value_cols=df.columns[1:])\n",
    "\n",
    "# Fill missing values in the time series using linear interpolation\n",
    "series = fill_missing_values(series)\n",
    "\n",
    "# Normalize the time series using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "series = TimeSeries.from_dataframe(series.pd_dataframe().dropna(), time_col='Timestamp', value_cols=df.columns[1:])\n",
    "series = TimeSeries.from_values(series.timestamp(), scaler.fit_transform(series.univariate_values()).T)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data, test_data = train_test_split(series, test_size=0.2, shuffle=False)\n",
    "\n",
    "class TransferredTransformerModel:\n",
    "    def __init__(self, input_chunk_length, output_chunk_length, num_heads, num_layers, d_model, d_ff, dropout=0.1):\n",
    "        self.input_chunk_length = input_chunk_length\n",
    "        self.output_chunk_length = output_chunk_length\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.dropout = dropout\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        inputs = Input(shape=(self.input_chunk_length, len(series.univariate_values())))\n",
    "        x = inputs\n",
    "\n",
    "        # Transformer Encoder\n",
    "        x = transformer.Encoder(\n",
    "            num_blocks=self.num_layers,\n",
    "            d_model=self.d_model,\n",
    "            num_heads=self.num_heads,\n",
    "            d_ff=self.d_ff,\n",
    "            dropout=self.dropout\n",
    "        )(x)\n",
    "\n",
    "        # Dense layer for anomaly detection\n",
    "        x = Dense(self.output_chunk_length, activation='sigmoid')(x)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=x)\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        return model\n",
    "\n",
    "    def fit(self, train_data, **kwargs):\n",
    "        # Convert the time series into supervised training data\n",
    "        train_data = train_data.pd_dataframe().dropna()\n",
    "        X = train_data[:-self.output_chunk_length].values.reshape(-1, self.input_chunk_length, len(series.univariate_values()))\n",
    "        y = train_data[self.input_chunk_length:].values.reshape(-1, self.output_chunk_length, len(series.univariate_values()))\n",
    "\n",
    "        # Train the model\n",
    "        self.model.fit(X, y, **kwargs)\n",
    "\n",
    "    def predict(self, n):\n",
    "        # Prepare the input data for prediction\n",
    "        last_chunk = series[-self.input_chunk_length:].univariate_values().reshape(1, self.input_chunk_length, len(series.univariate_values()))\n",
    "\n",
    "        # Predict the next n chunks of the time series\n",
    "        predictions = []\n",
    "        for _ in range(n):\n",
    "            next_chunk = self.model.predict(last_chunk)[0]\n",
    "\n",
    "            # Create the next time series chunk with the predicted values\n",
    "            next_values = np.concatenate([last_chunk[0, -1:, :], next_chunk], axis=0)\n",
    "            predictions.append(next_values[-self.output_chunk_length:])\n",
    "\n",
    "            last_chunk = np.concatenate([last_chunk[:, 1:, :], next_values.reshape(1, 1, -1)], axis=1)\n",
    "\n",
    "        # Create a TimeSeries object for the predictions\n",
    "        predicted_series = TimeSeries.from_values(timestamps[-n*self.output_chunk_length:], np.concatenate(predictions))\n",
    "\n",
    "        return predicted_series\n",
    "\n",
    "# Set hyperparameters for the model\n",
    "input_chunk_length = 10\n",
    "output_chunk_length = 1\n",
    "num_heads = 2\n",
    "num_layers = 2\n",
    "d_model = 32\n",
    "d_ff = 64\n",
    "dropout = 0.1\n",
    "\n",
    "# Create an instance of the transferred transformer model\n",
    "model = TransferredTransformerModel(input_chunk_length, output_chunk_length, num_heads, num_layers, d_model, d_ff, dropout=dropout)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, verbose=True)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(len(test_data))\n",
    "\n",
    "# Compute the mean squared error (MSE) for the predictions\n",
    "mse = metrics.mse(predictions, test_data)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245de87a-3564-4f7e-9f0c-b47323767c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyterhub] *",
   "language": "python",
   "name": "conda-env-jupyterhub-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
